{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d94ce-67bb-4c16-87f8-e0206c9c2799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import sys; sys.path.append('..')\n",
    "\n",
    "from bayesian_torch.models.dnn_to_bnn import dnn_to_bnn, get_kl_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lib.models.mlp import MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accf889f-71f9-43e1-97dc-d3944d22b956",
   "metadata": {},
   "source": [
    "# 3. Bayesian inference\n",
    "\n",
    "A plain feedforward network is not able to indicate uncertainty about its outputs. When it is given an input that differs a lot from the inputs it received during training, it produces an output with apparently the exact same amount of confidence as when it receives an input similar to the training data.\n",
    "\n",
    "This can be addressed by using Bayesian inference on the weights of the neural network. Instead of using determinstic values for the weights, the weights are represented by *probability distributions over possible values*. Formally, Bayesian inference computes the posterior distribution of the model weights given the training data: $P(\\mathbf{w}| \\mathcal{D})$. A single sample from this distribution contains a value for *all* the network weights of the model.\n",
    "\n",
    "Working directly with $P(\\mathbf{w}| \\mathcal{D})$, however, is not feasible for neural networks of any practical size. Instead, [Blundell et al. (2015)](https://arxiv.org/abs/1505.05424) propose to use a *variational approximation*. Variational learning finds the parameters $\\theta$ of a distribution on the weights $q(\\mathbf{w}|\\theta)$ such that the KL-divergence (a kind of *dissimilarity* measure) between $q(\\mathbf{w}|\\theta)$ and $P(\\mathbf{w}| \\mathcal{D})$ is minimized. In other words: we tweak the parameters $\\theta$ such that $q(\\mathbf{w}|\\theta)$ looks like $P(\\mathbf{w}| \\mathcal{D})$. \n",
    "\n",
    "This *KL-divergence* can be approximated by the following loss function:\n",
    "\n",
    "$$\n",
    "f(\\mathbf{w}, \\theta) = \\sum_{i=1}^n \\log q\\left(\\mathbf{w}^{(i)} \\mid \\theta\\right)-\\log P\\left(\\mathbf{w}^{(i)}\\right) -\\log P\\left(\\mathcal{D} \\mid \\mathbf{w}^{(i)}\\right)\n",
    "$$\n",
    "\n",
    "where $\\mathbf{w}^{(i)}$ is a random sample drawn from $q(\\mathbf{w}|\\theta)$. Note that the first two terms will be low when $q\\left(\\mathbf{w} \\mid \\theta\\right)$ is similar to the prior distribution over the weights $P\\left(\\mathbf{w}\\right)$, i.e., these terms **regularize** the model weights. The last term (the *likelihood cost*) will be low when the sampled network parameters $\\mathbf{w}^{(i)}$ can correctly predict the output of many input samples in the training dataset $\\mathcal{D}$.\n",
    "\n",
    "We want this loss function to be *differentiable* with respect to $\\theta$, such that gradients can be computed and a gradient descent-like optimization algorithm can be used to let $q(\\mathbf{w}|\\theta)$ be more similar to $P(\\mathbf{w}| \\mathcal{D})$.\n",
    "\n",
    "If we assume that $q(\\mathbf{w}|\\theta)$ is a diagonal Gaussian distribution, then $\\theta$ consists of a mean $\\mu$ and a standard deviation $\\sigma$ (note that each of these is a *vector* of the same length as the number of weights in the network). In that case, a sample $\\mathbf{w}^{(i)}$ can be obtained by drawing a random sample $\\epsilon^{(i)}$ from a unit Gaussian, shifting it by $\\mu$ and scaling it by $\\sigma$:\n",
    "\n",
    "$$\n",
    "\\mathbf w^{(i)} = \\mathbf\\mu + \\sigma\\odot \\epsilon,\n",
    "$$\n",
    "\n",
    "with $\\epsilon^{(i)}\\sim\\mathcal{N}(0, I)$ and $\\odot$ an element-wise multiplication. During training, we want to modify $\\mu$ and $\\sigma$ such that the loss function $f(\\mathbf{w}, \\theta)$ is minimized. Directly training $\\sigma$ might not be a good idea, as $\\sigma$ should be strictly positive and we do not have a guarantee that during training $\\sigma$ would only get positive values. Instead, we replace it by a [softplus](https://pytorch.org/docs/stable/generated/torch.nn.Softplus.html) function applied to a parameter $\\rho\\in\\mathbb R$:\n",
    "\n",
    "$$\n",
    "\\mathbf w^{(i)} = \\mathbf\\mu + \\underbrace{\\log\\left(1 + \\exp(\\mathbf\\rho)\\right)}_{= \\sigma}\\odot \\epsilon.\n",
    "$$\n",
    "\n",
    "Parameter $\\rho$ can get both positive and negative values; $\\sigma = \\log\\left(1 + \\exp(\\mathbf\\rho)\\right)$ is guaranteed to be positive.\n",
    "\n",
    "Now, the neural network can be optimized by repeating the following steps:\n",
    "\n",
    "1. Sample $\\epsilon^{(i)}\\sim\\mathcal N(0, I)$\n",
    "2. Let $\\mathbf w^{(i)} = \\mathbf\\mu + \\log\\left(1 + \\exp(\\mathbf\\rho)\\right)\\odot \\epsilon$\n",
    "3. Let $\\theta = (\\mu, \\rho)$\n",
    "4. Let $f(\\mathbf w, \\theta) = \\log q\\left(\\mathbf{w}^{(i)} \\mid \\theta\\right)-\\log P\\left(\\mathbf{w}^{(i)}\\right) P\\left(\\mathcal{D} \\mid \\mathbf{w}^{(i)}\\right)$\n",
    "5. Calculate the gradient of $f$ w.r.t. the mean $\\mu$\n",
    "7. Calculate the gradient of $f$ w.r.t. the standard deviation parameter $\\rho$\n",
    "8. Update the parameters of the variational posterior\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\mu \\leftarrow \\mu-\\alpha \\Delta_\\mu \\\\\n",
    "&\\rho \\leftarrow \\rho-\\alpha \\Delta_\\rho .\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5bde52-b598-4a1a-827b-cf8e67fe4dac",
   "metadata": {},
   "source": [
    "## 3.1 Moving an MLP into the Bayesian world\n",
    "\n",
    "With the library [BayesianTorch](https://github.com/IntelLabs/bayesian-torch), we can easily turn any MLP into a network that is ready for some Bayesian inference. Below, we show a code snippet of how you can do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c761ed-cad9-4095-b09c-0a40b9aededa",
   "metadata": {},
   "outputs": [],
   "source": [
    "const_bnn_prior_parameters = {\n",
    "    \"prior_mu\": 0.0,  # initialize μ of prior P(w), this will not be trained\n",
    "    \"prior_sigma\": 1.0,  # initialize σ of prior P(w), this will not be trained\n",
    "    \"posterior_mu_init\": 0.0,  # initialize μ of var. posterior q(w|θ)\n",
    "    \"posterior_rho_init\": -3.0,  # initialize ρ of var. posterior q(w|θ), with σ = log(1 + exp(ρ))\n",
    "    \"type\": \"Reparameterization\",  # Use algorithm from Blundell et al. (2015)\n",
    "    \"moped_enable\": False,\n",
    "}\n",
    "\n",
    "\n",
    "mlp = MLP(\n",
    "    num_input_neurons=1,\n",
    "    num_hidden_neurons=[100, 100],  # A two-layer network, each hidden layer has 100 neurons,\n",
    "    num_output_neurons=1,\n",
    "    activation='Tanh',\n",
    "    output_activation=None,\n",
    ")\n",
    "\n",
    "dnn_to_bnn(mlp, const_bnn_prior_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a27f0d-86f3-4b8a-8258-9cac640527f0",
   "metadata": {},
   "source": [
    "## 3.2 Bayesian training\n",
    "\n",
    "Thanks to BayesianTorch, training this network feel much like training any other network in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8431ab1-ee73-4de3-9e70-020ec10d1f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = 'runs_bayes'  # This is the name of the directory in which we will put the TensorBoard logs\n",
    "\n",
    "# Create a SummaryWriter instance with a meaningful run name\n",
    "timestamp = datetime.now().strftime('%Y-%M-%dT%H-%M-%S')  # We will append a timestamp to make the run name unique\n",
    "run_name = f'{mlp.num_hidden_neurons}_{timestamp}'\n",
    "writer = SummaryWriter(log_dir=f'{LOG_DIR}/{run_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542a7081",
   "metadata": {},
   "source": [
    "Start a new TensorBoard from the OnDemand dashboard with `anndl_es1_files/es1/runs_bayes` as value for the \"Project/Log folder\". You can kill the TensorBoard of the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145694f4-4308-424c-be86-67496b8f3706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "x_a = torch.linspace(-1, 0, 100)[:, None]\n",
    "x_b = torch.linspace(0, 1, 2)[:, None]\n",
    "x = torch.cat([x_a, x_b])\n",
    "y = x**2\n",
    "\n",
    "# Create an optimizer\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.01)\n",
    "\n",
    "# Create a loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "MAX_EPOCHS = 10000\n",
    "BATCH_SIZE = len(x)\n",
    "\n",
    "for epoch in tqdm(range(MAX_EPOCHS)):\n",
    "    output = mlp(x)\n",
    "    kl = get_kl_loss(mlp) / BATCH_SIZE  # KL divergence between q(w|θ) and the prior P(w)\n",
    "    mse_loss = loss_fn(output, y)  # Likelihood cost\n",
    "    loss = mse_loss + kl\n",
    "    writer.add_scalar('Loss/Train', loss, epoch)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849e414b-81f3-4a83-a6ba-d529b695ded9",
   "metadata": {},
   "source": [
    "## 3.3 Bayesian inference\n",
    "\n",
    "Since our MLP is stochastic now, the same input will yield different outputs. By passing the same input multiple times, we approximate the output distribution for that input (i.e., we perform a Monte Carlo simulation) and as such get an idea of how uncertain the network of the output it predicts for the given input. Below, we pass the same test dataset multiple times through the MLP and collect the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda00a7d-97f4-4117-adb6-f14a50cbe7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MONTE_CARLO = 1000\n",
    "\n",
    "x_test = torch.arange(-2, 2)[:, None]\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_preds = torch.hstack([\n",
    "        mlp(x_test)\n",
    "        for _ in tqdm(range(NUM_MONTE_CARLO))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007ba14-8ebd-4e91-b27b-01def0733ee6",
   "metadata": {},
   "source": [
    "We can compute the mean and standard deviation of the outputs that corresponded to the same inputs like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743b4b41-4098-4109-9f64-d5483f670271",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mean = y_preds.mean(dim=1)\n",
    "y_pred_std = y_preds.std(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2751653-e6df-4cff-af0f-c3dc78b74704",
   "metadata": {},
   "source": [
    "We can now visualize the mean of the predicted values, along with an error band that indicates the model's uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d9ded1-3e98-426d-98ee-c02d3be33bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_test, y_pred_mean.flatten())\n",
    "ax.fill_between(\n",
    "    x_test.flatten(),\n",
    "    (y_pred_mean - y_pred_std).flatten(),\n",
    "    (y_pred_mean + y_pred_std).flatten(),\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "ax.scatter(x, y.flatten(), s=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ff9448-5403-4d02-acb8-1e2de0bc4011",
   "metadata": {},
   "source": [
    "## 3.4 Exercise\n",
    "\n",
    "Train an MLP for Bayesian inference on the clean and noisy dataset you used in the previous exercise (from the function $y = \\sin(x^2)$) and compare it with the other training algorithms investigated there. Compare the test errors. Consider overparameterized networks (many neurons): do you see any improvement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efef1fa7-8e7a-408c-9218-cd4240711b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3da5c34a",
   "metadata": {},
   "source": [
    "# 4. Report\n",
    "\n",
    "Based on the previous exercises of section 2.5 and 3.4, write a report of maximum 4 pages (including text + figures) to discuss the main differences, (dis)advantages, speed, overfitting & generalization of different learning schemes. Show your understanding by explaining all concepts, interpreting your obtained results and making connections to the seen theory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
