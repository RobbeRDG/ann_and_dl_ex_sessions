{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f15d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "from lib.utils.tb_to_df import tb_to_df\n",
    "from lib.utils.pseudo_log import create_pseudo_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2a2dc0",
   "metadata": {},
   "source": [
    "# Extra: Analyzing TensorBoard Logs\n",
    "\n",
    "TensorBoard is a very nice tool to visualize the progress of your training. It is not always easy to thoroughly compare multiple runs, however. For that, you would need access to the raw logging data. To help you with that, we have create a function `tb_to_df` that converts all the TensorBoard logging data that is present a certain directory into a [`pandas` `DataFrame`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html). `pandas` is a Python library that provides tools to analyze tabular data. This tabular data is represented by `DataFrame` objects. In some way, `pandas` is like Excel for Python (but much better, of course ðŸ˜‰).\n",
    "\n",
    "Unfortunately, a `pandas` tutorial is beyond the scope of this course. Nevertheless, as it is a very powerful and popular tool, investing some time in learning to work with `pandas` is really worth it. But don't worry, you won't need any `pandas` know-how for this notebook.\n",
    "\n",
    "## Generate Some Dummy Logs\n",
    "\n",
    "For the sake of this example, we have written a small function that writes some dummy logs to a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcef13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the log root containing the dummy logs\n",
    "log_root = 'runs_dummy'\n",
    "\n",
    "# Clean up the directory if it exists\n",
    "if Path(log_root).exists():\n",
    "    shutil.rmtree(log_root)\n",
    "\n",
    "# Write some dummy logs to the directory\n",
    "create_pseudo_logs(log_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ef5617",
   "metadata": {},
   "source": [
    "## Converting TensorBoard Logs to `pandas`\n",
    "\n",
    "Once you have a directory that contains the logs of a couple of training runs, you pass the name of this directory to `tb_to_df()`, like so:\n",
    "\n",
    "```python\n",
    "from lib.utils.tb_to_df import tb_to_df\n",
    "\n",
    "log_root = 'runs_???'\n",
    "df = tb_to_df(log_root)\n",
    "```\n",
    "\n",
    "Then, `df` will contain all the logs stored in the given directory. Let's try this for the dummy logs we have created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9d71e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tb_to_df(log_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91901106",
   "metadata": {},
   "source": [
    "As you can see when executing the cell below, `df` contains a tabular data structure. Each row corresponds to a logging step. For each step of a certain training run, the `DataFrame` contains the logged scalars (`metric1` and `metric2` in our example) at that step and the time at which each of the scalars was logged (`wall_time (metric1)` and `wall_time (metric2)` in our example).\n",
    "\n",
    "Apart from the logged scalars, the `DataFrame` contains the value of the hyperparameters of the run. These values are extracted from the run name, as it is formatted like `hparam1(value1)_hparam2(value2)_`. This is the format we use in all our notebooks, so this hyperparameter parsing should work out of the box. Finally, the column `run_name` contains the name of the run to which the logged data belongs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1307fab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ded1fde",
   "metadata": {},
   "source": [
    "## Analyzing a `DataFrame`\n",
    "\n",
    "As mentioned above, we won't dive into the details of `DataFrame`s, but feel free to explore it yourself. With the [`seaborn`](https://seaborn.pydata.org/) plotting library, you can create some compelling data visualizations from a `DataFrame`.\n",
    "\n",
    "But again, there really is *no obligation to analyze your data with `pandas`*. If there's another software package that you feel comfortable with, please use that one! There's probably an easy way to convert the `DataFrame` into a format that your preferred software package supports. For example, you can save the `DataFrame` as an **Excel sheet** with the following line of code.\n",
    "\n",
    "> **NOTE**: You might get the error: `ModuleNotFoundError: No module named 'openpyxl'`. Simply open a new cell and run `!pip install openpyxl` to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9888d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('my_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be69904",
   "metadata": {},
   "source": [
    "Now, in the directory of this notebook, you should see a new file called `my_results.xlsx`. In Jupyter Notebook, you can click the checkmark next to it and then click the button `Download` on top of the file list.\n",
    "\n",
    "Alternatively, you can save the `DataFrame` as a **CSV-file** with the following line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e3d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('my_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055972fd",
   "metadata": {},
   "source": [
    "For other supported formats, see [the `pandas` documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
